{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 1: Pose classification with naive Bayes\n",
    "\n",
    "###### Submission deadline: 7 pm, Monday 12 Apr 2021"
   ]
  },
  {
   "source": [
    "**Student Name(s):**  'Jeremy Huang', 'Keyi Xiao'\n",
    "\n",
    "**Student ID(s):**     `1073721`\n",
    "                       `1046432`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Imports and default values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the important libaray for the project\n",
    "import pandas as pd; import numpy as np; import math\n",
    "import matplotlib.pyplot as plt; import copy\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "source": [
    "# Preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(the_data, missing_value):\n",
    "    \"\"\"\n",
    "       This function Reads file and converts it into a useful format for training and testing and return a dictionary\n",
    "    \"\"\"\n",
    "    training = pd.read_csv(the_data, header=None); means = []\n",
    "    \n",
    "    # Delete the rows with average value equals to 9999\n",
    "    trimmed = training[round(training.iloc[:,1:].mean(axis=1))!= missing_value].replace(9999, np.nan).reset_index(drop=True)\n",
    "    labels = list(trimmed[0]); labels = sorted(set(labels), key=labels.index); indexs = trimmed[0]\n",
    "    \n",
    "    # Make each pose a independent key in a dictionary and the data is put in them accordingly\n",
    "    classes = {}; new_class = {}\n",
    "    for name in labels:\n",
    "        classes[name] = [trimmed.iloc[i, 1:] for i in range(trimmed.shape[0]) if trimmed[0][i] == name]\n",
    "    \n",
    "    # To replace all np.nan to the mean from each point in each pose\n",
    "    for name in labels:\n",
    "        each = pd.DataFrame(classes[name]); means = list(each.describe().loc['mean'])\n",
    "        for i in range(22):\n",
    "            each.iloc[:, i] = each.iloc[:, i].replace(np.nan, means[i])\n",
    "        new_class[name] = each\n",
    "    \n",
    "    # To reshape the data and make it easy to train\n",
    "    result = new_class[list(new_class.keys())[0]]\n",
    "    for name in range(1, len(new_class.keys())):\n",
    "        result = result.append(new_class[list(new_class.keys())[name]])\n",
    "    result[0] = indexs; result = result.set_index(0)\n",
    "    \n",
    "    return labels, result"
   ]
  },
  {
   "source": [
    "# Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(labels, cleaned_data):\n",
    "    \"\"\"\n",
    "        This function calculates prior probabilities and return a trained model(a dictionary) with mean, standard deviation\n",
    "    \"\"\"\n",
    "    # Get labels and get teh prior for each pose(class)\n",
    "    prob_class =  [cleaned_data.loc[name].shape[0] for name in labels]\n",
    "    total = sum(prob_class)\n",
    "    for i in range(len(prob_class)):\n",
    "        prob_class[i] = prob_class[i]/total\n",
    "\n",
    "    # Make a dictionary contains all the features(prior, mean and std) needed to predict \n",
    "    model = {}; check = dict(zip(labels, prob_class))\n",
    "    for nam in labels:\n",
    "        small = cleaned_data.loc[nam].describe(); model[nam] = {'prior': check[nam]}\n",
    "        model[nam]['mean'] = list(small.loc['mean']); model[nam]['std'] = list(small.loc['std'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "source": [
    "# Predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(labels, cleaned_data, model):\n",
    "    '''\n",
    "        This function predicts classes for new items in a test dataset (re-use the training data as a test set)\n",
    "    '''\n",
    "    # Loop through the training data to collect the result after predicting\n",
    "    prediction = []; label_name = labels.copy()\n",
    "        \n",
    "    for idx in range(cleaned_data.shape[0]):\n",
    "        name = list(cleaned_data.index.tolist())[idx]\n",
    "        instance = cleaned_data.iloc[idx, :]\n",
    "        score = []\n",
    "\n",
    "        for pose in model.keys():\n",
    "            # Prior probability from each class            \n",
    "            probs = math.log2(model[pose]['prior'])\n",
    "\n",
    "            # Likelihoods plus the prior from class using log\n",
    "            for i, value in enumerate(instance):\n",
    "                mu = model[pose]['mean'][i]; sigma = model[pose]['std'][i]\n",
    "                if value == 0:\n",
    "                    probs += 10**(-256)\n",
    "                else:\n",
    "                    probs += (-(value - mu)**2/ (2*sigma**2) - math.log2(math.sqrt(2*math.pi*sigma**2)))\n",
    "            score.append(probs)\n",
    "        # Collect index ,true name labels and the predicted name    \n",
    "        prediction.append([idx, name, label_name[np.argmax(score)]])\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "source": [
    "# Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(labels, predictions, beta = 1):\n",
    "    '''\n",
    "        This function evaluate the prediction performance by comparing the model’s class outputs and truth labels\n",
    "    '''\n",
    "    # Make a confusion matrix for better evaluating\n",
    "    predicts = pd.DataFrame(predictions, columns=['index', 'actual','predict']).set_index('index')\n",
    "    total = predicts.shape[0]; true_label = predicts['actual']; predict_label = predicts['predict']\n",
    "    confusion_dict = {}; confusion = pd.crosstab(true_label, predict_label); total_TP = []; total_precision = []\n",
    "    total_recall = []; total_F_score = []\n",
    "\n",
    "    # Get the performance data from confusion matrix\n",
    "    for name in labels:\n",
    "        confusion_dict[name] = {'TFPN': [], 'precision': 0.0, 'recall': 0.0, 'F-score': 0.0}\n",
    "        TP = confusion[name][name]; FP = sum(confusion.loc[name]) - TP\n",
    "        FN = sum(confusion[name]) - TP; TN = total - (TP + FP + FN)\n",
    "        precision = TP / (TP + FP); recall = TP / (TP + FN)\n",
    "        F_score = ((1 + beta * beta) * precision * recall) / ((beta * beta * precision) + recall)\n",
    "        confusion_dict[name]['TFPN'] = [TP, FP, FN, TN]\n",
    "        confusion_dict[name]['precision'] = precision; confusion_dict[name]['recall'] = recall\n",
    "        confusion_dict[name]['F_score'] = F_score\n",
    "        total_TP.append(TP); total_precision.append(precision)\n",
    "        total_recall.append(recall); total_F_score.append(F_score)\n",
    "    \n",
    "\n",
    "    # Print performance analysis for all data and each class\n",
    "    print(\"Correct Prection: {}\\nTotal_Accuracy: {}\\nTotal_Precision: {}\\nTotal_Recall: {}\\nTotal_F_score: {}\\n\".format(sum(total_TP), (sum(total_TP) / total), (sum(total_precision) / len(labels)), (sum(total_recall) / len(labels)), (sum(total_F_score) / len(labels)) ))\n",
    "    print(\"-------------------------\")\n",
    "    for name in labels:\n",
    "        print(\"Pose : {}\\n*********************\\nTP, FP, FN, TN: {}\\nPrecision: {}\\nRecall: {}\\nF_score: {}\\n\".format(name,\\\n",
    "                confusion_dict[name]['TFPN'], confusion_dict[name]['precision'], \n",
    "                confusion_dict[name]['recall'], confusion_dict[name]['F_score']))\n",
    "    \n",
    "    return confusion_dict"
   ]
  },
  {
   "source": [
    "# Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. Prepocess \n",
    "      |\n",
    "      |\n",
    "     \\|/\n",
    "# 2. Train\n",
    "      |\n",
    "      |\n",
    "     \\|/\n",
    "# 3. Predict\n",
    "      |\n",
    "      |\n",
    "     \\|/\n",
    "# 4. Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get information from \"README.txt\" from Canvas\n",
    "train_data = 'train.csv'; test_data = 'test.csv'; not_detected = 9999; index_num = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Correct Prection: 650\nTotal_Accuracy: 0.8879781420765027\nTotal_Precision: 0.8903779417864419\nTotal_Recall: 0.9026112839276113\nTotal_F_score: 0.8870969959345972\n\n-------------------------\nPose : bridge\n*********************\nTP, FP, FN, TN: [38, 40, 5, 649]\nPrecision: 0.48717948717948717\nRecall: 0.8837209302325582\nF_score: 0.628099173553719\n\nPose : childs\n*********************\nTP, FP, FN, TN: [59, 4, 1, 668]\nPrecision: 0.9365079365079365\nRecall: 0.9833333333333333\nF_score: 0.9593495934959351\n\nPose : downwarddog\n*********************\nTP, FP, FN, TN: [94, 4, 42, 592]\nPrecision: 0.9591836734693877\nRecall: 0.6911764705882353\nF_score: 0.8034188034188035\n\nPose : mountain\n*********************\nTP, FP, FN, TN: [148, 12, 0, 572]\nPrecision: 0.925\nRecall: 1.0\nF_score: 0.961038961038961\n\nPose : plank\n*********************\nTP, FP, FN, TN: [53, 4, 5, 670]\nPrecision: 0.9298245614035088\nRecall: 0.9137931034482759\nF_score: 0.9217391304347825\n\nPose : seatedforwardbend\n*********************\nTP, FP, FN, TN: [41, 1, 0, 690]\nPrecision: 0.9761904761904762\nRecall: 1.0\nF_score: 0.9879518072289156\n\nPose : tree\n*********************\nTP, FP, FN, TN: [67, 0, 13, 652]\nPrecision: 1.0\nRecall: 0.8375\nF_score: 0.9115646258503401\n\nPose : trianglepose\n*********************\nTP, FP, FN, TN: [56, 3, 6, 667]\nPrecision: 0.9491525423728814\nRecall: 0.9032258064516129\nF_score: 0.9256198347107438\n\nPose : warrior1\n*********************\nTP, FP, FN, TN: [44, 10, 3, 675]\nPrecision: 0.8148148148148148\nRecall: 0.9361702127659575\nF_score: 0.8712871287128713\n\nPose : warrior2\n*********************\nTP, FP, FN, TN: [50, 4, 7, 671]\nPrecision: 0.9259259259259259\nRecall: 0.8771929824561403\nF_score: 0.9009009009009009\n\n"
     ]
    }
   ],
   "source": [
    "labels, cleaned = preprocess(train_data, not_detected) # Use the train.csv as the training data\n",
    "\n",
    "trained = train(labels, cleaned) # Train a model from preprocessed train.csv\n",
    "\n",
    "predictions = predict(labels, cleaned, trained) # To collect the prediction from the trained model\n",
    "\n",
    "evaluations = evaluate(labels, predictions) # Evaluate the overall performance according to each pose(class) and print them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "If you are in a group of 2, you will respond to **four** questions of your choosing.\n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer should be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Since this is a multiclass classification problem, there are multiple ways to compute precision, recall, and F-score for this classifier. Implement at least two of the methods from the \"Model Evaluation\" lecture and discuss any differences between them. (The implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Micro_average_precision: 0.8879781420765027\nMicro_average_recall:    0.8879781420765027\nMicro_average_F_score:   0.8879781420765027\n-------------------------------------------\nMacro_average_precision: 0.8903779417864419\nMacro_average_recall:    0.9026112839276113\nMacro_average_F_score:   0.8870969959345972\n\n"
     ]
    }
   ],
   "source": [
    "True_Positive = []; False_Positive = []; False_negative = []; Total_Precision = []; Total_Recall = []; Total_F_Score = []\n",
    " \n",
    "for name in labels:\n",
    "    the_info = evaluations[name]\n",
    "    # Collect all the performance data\n",
    "    True_Positive.append(the_info['TFPN'][0]); False_Positive.append(the_info['TFPN'][1]); False_negative.append(the_info['TFPN'][2])\n",
    "    Total_Precision.append(the_info['precision']); Total_Recall.append(the_info['recall']); Total_F_Score.append(the_info['F_score'])\n",
    "\n",
    "TP_Sum = sum(True_Positive); FP_Sum = sum(False_Positive); FN_Sum = sum(False_negative)\n",
    "\n",
    "# Micro Average Values\n",
    "micro_average_precision = TP_Sum / (TP_Sum + FP_Sum)\n",
    "micro_average_recall = TP_Sum / (TP_Sum + FN_Sum)\n",
    "micro_average_F_score = (2 * micro_average_precision * micro_average_recall) / ((1 * micro_average_precision) + micro_average_recall)\n",
    "\n",
    "# Macro Average Values\n",
    "macro_average_precision = sum(Total_Precision) / len(labels)\n",
    "macro_average_recall = sum(Total_Recall) / len(labels)\n",
    "macro_average_F_score = sum(Total_F_Score) / len(labels)\n",
    "\n",
    "print(\"Micro_average_precision: {}\\nMicro_average_recall:    {}\\nMicro_average_F_score:   {}\\n-------------------------------------------\\nMacro_average_precision: {}\\nMacro_average_recall:    {}\\nMacro_average_F_score:   {}\\n\".format(micro_average_precision, micro_average_recall, micro_average_F_score, macro_average_precision, \\\n",
    "    macro_average_recall, macro_average_F_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "The Gaussian naıve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in this dataset? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the classifier’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for name in labels:\n",
    "    test_model = trained[name]\n",
    "    space = []\n",
    "    for feature in range(len(test_model['mean'])):\n",
    "        # Get mean and std, then make a table to fit the data\n",
    "        mu = test_model['mean'][feature]; sigma = test_model['std'][feature]\n",
    "        each_feature = cleaned.loc[name].iloc[feature]\n",
    "        matrix = np.linspace(min(each_feature), max(each_feature))\n",
    "\n",
    "        # Plotting\n",
    "        plt.hist(each_feature, bins=30, density=True)\n",
    "        plt.plot(matrix, norm.pdf(matrix, mu, sigma))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Implement a kernel density estimate (KDE) naive Bayes classifier and compare its performance to the Gaussian naive Bayes classifier. Recall that KDE has kernel bandwidth as a free parameter -- you can choose an arbitrary value for this, but a value in the range 5-25 is recommended. Discuss any differences you observe between the Gaussian and KDE naive Bayes classifiers. (As with the Gaussian naive Bayes, this KDE naive Bayes implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def kdeTrain(labels, cleaned_data):\n",
    "    \"\"\"\n",
    "        This function calculates prior probabilities and return a trained model(a dictionary) with points\n",
    "    \"\"\"\n",
    "    # Get labels and get teh prior for each pose(class)\n",
    "    prob_class =  [cleaned_data.loc[name].shape[0] for name in labels]\n",
    "    total = sum(prob_class)\n",
    "    for i in range(len(prob_class)):\n",
    "        prob_class[i] = prob_class[i]/total\n",
    "\n",
    "    # Make a dictionary contains all the features(prior, mean and std) needed to predict \n",
    "    model = {}; check = dict(zip(labels, prob_class))\n",
    "    for nam in labels:\n",
    "        small = cleaned_data.loc[nam].reset_index(drop=True)\n",
    "        model[nam] = {'prior': check[nam]}; model[nam]['point'] = small\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdePredict(labels, cleaned_data, model):\n",
    "    '''\n",
    "        This function predicts classes for new items in a test dataset (re-use the training data as a test set)\n",
    "    '''\n",
    "    # Loop through the training data to collect the result after predicting\n",
    "    prediction = []; label_name = labels.copy()\n",
    "        \n",
    "    for idx in range(cleaned_data.shape[0]):\n",
    "        name = list(cleaned_data.index.tolist())[idx]\n",
    "        score = []; k = 5\n",
    "        for pose in model.keys():\n",
    "            # Prior probability from each class            \n",
    "            probs = math.log2(model[name]['prior'])\n",
    "            # Likelihoods plus the prior from class using log\n",
    "            for i in range(1, model[pose]['point'].shape[0]):\n",
    "                each_diff = []; each_pdf = []\n",
    "                \n",
    "                # Get all the difference from test point to each point\n",
    "                for x_test in model[pose]['point'].loc[i]:\n",
    "                    x_test = float(x_test)\n",
    "                    for x_train in model[pose]['point'].loc[i]:\n",
    "                        x_train = float(x_train)\n",
    "                        each_diff.append(x_test - x_train)\n",
    "\n",
    "                # Get all the pdf from each difference \n",
    "                for diff in each_diff:\n",
    "                    each_pdf.append(norm.pdf(diff, 0, k))\n",
    "                probs += math.log2(sum(each_pdf) / model[pose]['point'].shape[0])\n",
    "            score.append(probs)\n",
    "        # Collect index ,true name labels and the predicted name    \n",
    "        prediction.append([idx, name, label_name[np.argsort(score)[-2]]])\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_label, kde_test = preprocess(test_data, not_detected)\n",
    "kde_trained = kdeTrain(kde_label, kde_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1     126.835800\n",
       "2      99.927500\n",
       "3     -55.201525\n",
       "4     -40.689275\n",
       "5      47.555100\n",
       "6      -9.784800\n",
       "7       7.377900\n",
       "8     -65.100400\n",
       "9     -62.378800\n",
       "10    -80.844800\n",
       "11    -63.587400\n",
       "12      2.479700\n",
       "13    -14.561300\n",
       "14    -57.158950\n",
       "15    -90.310600\n",
       "16    -30.339200\n",
       "17    -41.216300\n",
       "18     23.314600\n",
       "19     57.562500\n",
       "20    -24.693000\n",
       "21     61.509400\n",
       "22    -34.056500\n",
       "Name: 0, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "kde_trained['bridge']['point'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['bridge', -3.0]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['childs', -3.222392421336448]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['downwarddog', -2.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['mountain', -1.9004643264490855]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['plank', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['seatedforwardbend', -3.6374299206152916]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['tree', -4.222392421336448]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['trianglepose', -4.807354922057605]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior1', -4.485426827170242]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n['warrior2', -3.807354922057604]\n"
     ]
    }
   ],
   "source": [
    "kdePredict = kdePredict(labels, kde_test, kde_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-49d476a72b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkdePredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-a0dc5feab87a>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(labels, predictions, beta)\u001b[0m\n\u001b[0;32m      4\u001b[0m     '''\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Make a confusion matrix for better evaluating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'actual'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mtrue_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mpredict_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mconfusion_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mtotal_TP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mtotal_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "evaluate(labels, kdePredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Instead of using an arbitrary kernel bandwidth for the KDE naive Bayes classifier, use random hold-out or cross-validation to choose the kernel bandwidth. Discuss how this changes the model performance compared to using an arbitrary kernel bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Naive Bayes ignores missing values, but in pose recognition tasks the missing values can be informative. Missing values indicate that some part of the body was obscured and sometimes this is relevant to the pose (e.g., holding one hand behind the back). Are missing values useful for this task? Implement a method that incorporates information about missing values and demonstrate whether it changes the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "Engineer your own pose features from the provided keypoints. Instead of using the (x,y) positions of keypoints, you might consider the angles of the limbs or body, or the distances between pairs of keypoints. How does a naive Bayes classifier based on your engineered features compare to the classifier using (x,y) values? Please note that we are interested in explainable features for pose recognition, so simply putting the (x,y) values in a neural network or similar to get an arbitrary embedding will not receive full credit for this question. You should be able to explain the rationale behind your proposed features. Also, don't forget the conditional independence assumption of naive Bayes when proposing new features -- a large set of highly-correlated features may not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}